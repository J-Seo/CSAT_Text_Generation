{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/jaehyungseo/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/jaehyungseo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jaehyungseo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/jaehyungseo/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/jaehyungseo/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/jaehyungseo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jaehyungseo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/jaehyungseo/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/jaehyungseo/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/jaehyungseo/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/jaehyungseo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jaehyungseo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/jaehyungseo/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.summarization import summarize\n",
    "from newspaper import Article\n",
    "from model import Model\n",
    "from utils import build_dict, build_dataset, batch_iter\n",
    "from rouge import Rouge\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "import nltk \n",
    "from nltk.tag import pos_tag\n",
    "from nltk import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import sym_vocab\n",
    "import ant_vocab\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "# import tensorflow as tf\n",
    "import nltk, re, pprint\n",
    "import docx2txt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import ant_vocab\n",
    "\n",
    "\n",
    "# download \n",
    "nltk.download('words')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지문 생성 및 문제 생성을 위한 텍스트 파일 생성 \n",
    "def crawl_news(url, raw_txt_name, num_words):\n",
    "    # URL 기반 크롤링, 언어는 영어로 설정\n",
    "    news = Article(url, language = 'en') # URL 가져오기\n",
    "    news.download() # 해당 url의 html을 가져오기\n",
    "    news.parse() # html 파싱\n",
    "    \n",
    "    print(news.text)\n",
    "    # 지정된 단어 갯수를 기준으로 textrank를 적용하여 파싱된 텍스트를 요약 (Rule base)\n",
    "    text = summarize(news.text, word_count = num_words) # 600자 기준으로 하기\n",
    "    title = news.title # 파싱한 html에서 title에 해당하는 부분 추출하기\n",
    "    title = title.lower() # title에 대해서 전부 소문자화 \n",
    "    \n",
    "    title = re.sub('\\([^)]*\\)', '', title) # 괄호를 포함한 문자열 제거 \n",
    "    \n",
    "    # 크롤링한 raw data를 별도로 저장\n",
    "    with open(raw_txt_name, 'w', encoding = 'utf-8') as f: # 크롤링한 raw data를 저장하기\n",
    "        f.write(text)\n",
    "    \n",
    "    text = re.sub('\\n', ' ', text) # raw data에서 불필요한 줄바꿈표 제거 (상대적일듯)\n",
    "\n",
    "    return text, title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 빈칸 지문 생성을 위한 함수를 별도로 정의\n",
    "def bf_create_order(raw_txt_name, prepro_txt_name):\n",
    "    # 문장 번호: 문장 형식의 저장을 위해 변수 생성\n",
    "    test_dict = {}\n",
    "    \n",
    "    # 저장했었던 크롤링 본문 데이터 불러오기\n",
    "    with open(raw_txt_name, 'r', encoding = 'utf-8') as f:\n",
    "    # raw data 상태에서 전처리를 통해 모델에 들어갈 수 있는 데이터셋으로 변형\n",
    "        for idx, text in enumerate(f.readlines()):\n",
    "            # print(idx, text)\n",
    "            #text = text.lower() # 소문자로 통일\n",
    "            text = re.sub('[.]', '', text) # 일단 온점 모두 제거\n",
    "            #text = re.sub('[,]', ' ,', text) # 반점 하나의 단어로 인식\n",
    "            #text = re.sub(\"\\’s\",' \\'s', text) # 소유격도 하나의 단어로 인식\n",
    "            #text = re.sub(\"[0-9]\", '#', text) # 숫자를 #로 치환\n",
    "            #text = re.sub(\"'.+'\", '', text) # 작은 따옴표 안 고유명사 제거 \n",
    "            #text = re.sub('[“”]', '', text) # 큰 따옴표 제거 \n",
    "            text = re.sub('\\n', '', text) # 줄 바꿈표 제거 \n",
    "            print(idx, text)\n",
    "        \n",
    "            # 사전에 저장하기\n",
    "            test_dict[idx] = text ## {1: '텍스트', 2: '텍스트'}\n",
    "            \n",
    "    # 전처리된 데이터를 별도의 파일로 저장\n",
    "    with open(prepro_txt_name, 'w', encoding = 'utf-8') as f: # 전처리한 데이터를 저장하기 \n",
    "        # 줄 바꿈을 기준으로 문장을 구분하여 저장\n",
    "        for i in range(len(test_dict)):\n",
    "            test_dict[i] = test_dict[i] + \" \" + \".\" + '\\n'\n",
    "            f.write(test_dict[i])\n",
    "    \n",
    "    return test_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 요약 학습 데이터 불러오기\n",
    "def shake_bot_order(filename, vaild_article_path):\n",
    "    # 설정된 세팅 값 불러오기\n",
    "    with open(\"args.pickle\", \"rb\") as f:\n",
    "        args = pickle.load(f)\n",
    "        \n",
    "    # 실행시 최초의 상태로 초기화하여 모델 재사용이 가능하도록 함\n",
    "    tf.reset_default_graph()\n",
    "    # 학습된 단어 사전과 본문 최대 길이와 요약 최대 길이 설정 값을 불러옴\n",
    "    print(\"셰봇이 단어 사전 불러오는 중...\")\n",
    "    word_dict, reversed_dict, article_max_len, summary_max_len = build_dict(\"valid\", args.toy)\n",
    "    # 불러온 설정 값에 따라서 검증 데이터셋을 생성\n",
    "    print(\"셰봇이 기본 설정 값 초기화 중...\")\n",
    "    valid_x = build_dataset(\"valid\", vaild_article_path, word_dict, article_max_len, summary_max_len, args.toy)\n",
    "    valid_x_len = [len([y for y in x if y != 0]) for x in valid_x]\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        # 학습된 체크포인트와 모델을 불러오기 \n",
    "        print(\"Loading saved model...\")\n",
    "        model = Model(reversed_dict, article_max_len, summary_max_len, args, forward_only=True) # 검증 단계\n",
    "        saver = tf.train.Saver(tf.global_variables())\n",
    "        ckpt = tf.train.get_checkpoint_state(\"./saved_model/\")\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        \n",
    "        # 검증을 진행할 배치 사이즈 설정\n",
    "        batches = batch_iter(valid_x, [0] * len(valid_x), args.batch_size, 1)\n",
    "        \n",
    "        # 검증 단계인 만큼 인코더 인풋 부분만 고려하여 학습 진행\n",
    "        print(\"셰봇이 수능 순서 문제 생성 준비 중.. {}...\".format(filename))\n",
    "        for batch_x, _ in batches:\n",
    "            # 문장 -> 문장 예측이 가능하도록 데이터 분할 \n",
    "            batch_x_len = [len([y for y in x if y != 0]) for x in batch_x]\n",
    "            # 검증을 위한 배치에 따라 모델 및 데이터 셋 설정 준비 \n",
    "            valid_feed_dict = {\n",
    "                model.batch_size: len(batch_x),\n",
    "                model.X: batch_x,\n",
    "                model.X_len: batch_x_len,\n",
    "            }\n",
    "            # Prediction을 목적으로 학습된 모델을 검증을 위한 설정 값을 적용하여 예측 결과 생성\n",
    "            prediction = sess.run(model.prediction, feed_dict=valid_feed_dict)\n",
    "            # 인덱스 -> 단어 사전을 통해 학습된 결과를 단어로 표현.\n",
    "            prediction_output = [[reversed_dict[y] for y in x] for x in prediction[:, 0, :]]\n",
    "            \n",
    "            # 생성된 예측 결과물을 문장 단위로 저장 \n",
    "            with open(filename, \"w\") as f:\n",
    "                for line in prediction_output:\n",
    "                    summary = list()\n",
    "                    for word in line:\n",
    "                        if word == \"</s>\":\n",
    "                            break\n",
    "                        if word not in summary:\n",
    "                            summary.append(word)\n",
    "                    print(\" \".join(summary), file=f)\n",
    "                    \n",
    "            #with open('./rouge_test/sys_dir/{}.txt'.format(filename), \"w\") as f:\n",
    "                #for line in prediction_output:\n",
    "                    #summary = list()\n",
    "                    #for word in line:\n",
    "                        #if word == \"</s>\":\n",
    "                            #break\n",
    "                        #if word not in summary:\n",
    "                            #summary.append(word)\n",
    "                    #print(\" \".join(summary), file=f)\n",
    "\n",
    "        print('셰봇이가 5지 선다로 쓸만한 친구들을 추려냈어요.. {}...'.format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_order_sentence(test_dict):\n",
    "    \n",
    "    # 제시 문장 \n",
    "    main_set = test_dict[0]\n",
    "    \n",
    "    # 몇개의 문장씩 나눌 것인지 결정\n",
    "    divide_num = (int(len(test_dict)-1)) // 3\n",
    "    remain_num = (int(len(test_dict)-1)) % 3\n",
    "    \n",
    "    if divide_num >= remain_num * 2:\n",
    "        # divide_num이 2개 이므로 1을 빼면 2를 뺀 효과\n",
    "        divide_num = int(divide_num - 1) \n",
    "        # 따라서 remain_num에 +2를 해야함. \n",
    "        remain_num = int(remain_num + 2)\n",
    "    \n",
    "    # 랜덤하게 배정하기 위한 리스트 형성\n",
    "    assign_list = [int(divide_num), int(divide_num), int(remain_num)]\n",
    "    random.shuffle(assign_list)\n",
    "    \n",
    "    # 배정받은 수만큼 문장 나누기\n",
    "    first_set = list()\n",
    "    second_set = list()\n",
    "    third_set = list()\n",
    "    \n",
    "    # 첫번째 할당\n",
    "    for n in range(1, assign_list[0] + 1):\n",
    "        first_set.append(test_dict[n].capitalize())\n",
    "        \n",
    "    # 두번째 할당\n",
    "    for n in range(assign_list[0] + 1, assign_list[0] + assign_list[1] + 1):\n",
    "        second_set.append(test_dict[n].capitalize())\n",
    "        \n",
    "    # 세번째 할당\n",
    "    for n in range(assign_list[0] + assign_list[1] + 1, assign_list[0] + assign_list[1] + assign_list[2] + 1):\n",
    "        third_set.append(test_dict[n].capitalize())\n",
    "    \n",
    "    return main_set, first_set, second_set, third_set # 아직 배열 되어 있지 않은 상황. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_order_sentence2(test_dict):\n",
    "    \n",
    "    # 제시 문장 \n",
    "    main_set = test_dict[0]\n",
    "    \n",
    "    # 몇개의 문장씩 나눌 것인지 결정\n",
    "    \n",
    "    divide_num = (int(len(test_dict)-1)) // 5 # 5개의 분할\n",
    "\n",
    "    remain_num = (int(len(test_dict)-1)) % 5 # 5개의 분할 중 마지막 남은 것 (크게 차이가 없을 것)\n",
    "    \n",
    "    # 랜덤하게 배정하기 위한 리스트 형성\n",
    "    # 나머지가 존재하는 경우\n",
    "    if remain_num != 0:\n",
    "    \n",
    "        assign_list = [int(divide_num), int(divide_num), int(divide_num), int(divide_num), int(remain_num)]\n",
    "    \n",
    "        random.shuffle(assign_list)\n",
    "    # 나머지가 존재하지 않고 나누어 떨어지는 경우 \n",
    "    elif remain_num == 0:\n",
    "        \n",
    "        assign_list = [int(divide_num), int(divide_num), int(divide_num), int(divide_num), int(divide_num)]\n",
    "    \n",
    "        random.shuffle(assign_list)\n",
    "    \n",
    "    # 배정받은 수만큼 문장 나누기\n",
    "    first_set = list()\n",
    "    second_set = list()\n",
    "    third_set = list()\n",
    "    fourth_set = list()\n",
    "    fifth_set = list()\n",
    "    \n",
    "    # 첫번째 할당\n",
    "    for n in range(1, assign_list[0] + 1):\n",
    "        first_set.append(test_dict[n].capitalize())\n",
    "    # 두번째 할당\n",
    "    for n in range(assign_list[0] + 1, assign_list[0] + assign_list[1] + 1):\n",
    "        second_set.append(test_dict[n].capitalize())\n",
    "    # 세번째 할당\n",
    "    for n in range(assign_list[0] + assign_list[1] + 1, assign_list[0] + assign_list[1] + assign_list[2] + 1):\n",
    "        third_set.append(test_dict[n].capitalize())\n",
    "    # 네번째 할당\n",
    "    for n in range(assign_list[0] + assign_list[1] + assign_list[2] + 1, assign_list[0] + assign_list[1] + assign_list[2] + assign_list[3] + 1):\n",
    "        fourth_set.append(test_dict[n].capitalize())\n",
    "    # 다섯번째 할당 \n",
    "    for n in range(assign_list[0] + assign_list[1] + assign_list[2] + assign_list[3] + 1, assign_list[0] + assign_list[1] + assign_list[2] + assign_list[3] + assign_list[4] + 1):\n",
    "        fifth_set.append(test_dict[n].capitalize())\n",
    "    \n",
    "    return main_set, first_set, second_set, third_set, fourth_set, fifth_set # 아직 배열 되어 있지 않은 상황. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rouge Score를 통해 학습 완성도가 높은 문장을 선별 \n",
    "def for_rouge_test(summy, label):\n",
    "    rouge_dict = {}\n",
    "    rouge_list = []\n",
    "    rouge = Rouge()\n",
    "    # 학습 결과로 예측한 결과물 불러오기    \n",
    "    with open(summy, 'r', encoding = 'utf-8') as f:\n",
    "            \n",
    "        for idx, line in enumerate(f.readlines()):\n",
    "            \n",
    "            # 실제 문장 - 예측 결과에서 학습의 정도를 Rouge-r과 Rouge-p로 검증\n",
    "            scores = rouge.get_scores(line, label[idx])\n",
    "            \n",
    "            p_score = scores[0][\"rouge-1\"][\"p\"] \n",
    "            r_score = scores[0][\"rouge-1\"][\"r\"] \n",
    "            \n",
    "            if r_score > 0:\n",
    "            \n",
    "                r_idx_score = (idx, r_score)            \n",
    "                \n",
    "                rouge_list.append(r_idx_score)\n",
    "                # print(rouge_list)\n",
    "            \n",
    "                rouge_dict[idx] = line\n",
    "            \n",
    "            \n",
    "        rouge_list = sorted(rouge_list, key = lambda rouge_list: rouge_list[1], reverse=True)\n",
    "        \n",
    "        rouge_list = rouge_list[:5]\n",
    "        \n",
    "        sort_rouge_list = sorted(rouge_list, key = lambda rouge_list: rouge_list[0], reverse=False)\n",
    "                \n",
    "        question_list = []\n",
    "    \n",
    "        for ix in sort_rouge_list:\n",
    "            \n",
    "            question_list.append(rouge_dict[ix[0]])\n",
    "          \n",
    "    return question_list, sort_rouge_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "People who’ve spoken to Mr. Patrick say he sees an opportunity in the flagging poll numbers of Senators Kamala Harris and Cory Booker, the two major black candidates already in the race. If he can do decently well in early-voting New Hampshire, his neighboring state, he may gain support in South Carolina, where the majority of the primary electorate is black, the thinking goes.\n",
      "\n",
      "The obstacles to this plan are obvious: money and manpower. Having been out of public life for nearly five years, Mr. Patrick has no list of donors to tap. And, at such a late date, he’s scrambling to assemble a team, pulling in former staff members of Beto O’Rourke.\n",
      "\n",
      "Money isn’t a problem for Mr. Bloomberg, whose net worth is estimated to be more than $52 billion. But the first Iowa poll to include Mr. Bloomberg since news broke of his possible bid shows him with a negative 31 percent approval rating, making him the least popular candidate in the field. In New Hampshire, 54 percent of likely primary voters already say they would definitely not vote for him.\n",
      "\n",
      "Those low numbers along with the shrinking calendar are the reasons Mr. Bloomberg is said to be considering an untraditional strategy of skipping the first four nominating states. He’d then carpet-bomb the more expensive media markets of the Super Tuesday contests with television advertising — the main way to reach voters in vast states like California and Texas that vote March 3.\n",
      "\n",
      "It’s a theory that has been attempted in more modest ways by other candidates — Rudy Giuliani in 2008 and Jerry Brown in 1976 — and met with failure. Success in the early-voting states offers proof that a candidate can do what Democrats, particularly in this election, want most of all: to win. Wait until March to make that case, and you might be too late.\n",
      "\n",
      "Money matters in politics. But so does momentum.\n",
      "0 People who’ve spoken to Mr Patrick say he sees an opportunity in the flagging poll numbers of Senators Kamala Harris and Cory Booker, the two major black candidates already in the race\n",
      "1 If he can do decently well in early-voting New Hampshire, his neighboring state, he may gain support in South Carolina, where the majority of the primary electorate is black, the thinking goes\n",
      "2 The obstacles to this plan are obvious: money and manpower\n",
      "3 Having been out of public life for nearly five years, Mr Patrick has no list of donors to tap\n",
      "4 And, at such a late date, he’s scrambling to assemble a team, pulling in former staff members of Beto O’Rourke\n",
      "5 Money isn’t a problem for Mr Bloomberg, whose net worth is estimated to be more than $52 billion\n",
      "6 But the first Iowa poll to include Mr Bloomberg since news broke of his possible bid shows him with a negative 31 percent approval rating, making him the least popular candidate in the field\n",
      "7 In New Hampshire, 54 percent of likely primary voters already say they would definitely not vote for him\n",
      "8 Those low numbers along with the shrinking calendar are the reasons Mr Bloomberg is said to be considering an untraditional strategy of skipping the first four nominating states\n",
      "9 He’d then carpet-bomb the more expensive media markets of the Super Tuesday contests with television advertising — the main way to reach voters in vast states like California and Texas that vote March 3\n",
      "10 It’s a theory that has been attempted in more modest ways by other candidates — Rudy Giuliani in 2008 and Jerry Brown in 1976 — and met with failure\n",
      "11 Success in the early-voting states offers proof that a candidate can do what Democrats, particularly in this election, want most of all: to win\n",
      "12 Wait until March to make that case, and you might be too late\n",
      "13 Money matters in politics\n",
      "14 But so does momentum\n",
      "① If he can do decently well in early-voting new hampshire, his neighboring state, he may gain support in south carolina, where the majority of the primary electorate is black, the thinking goes. The obstacles to this plan are obvious: money and manpower.\n",
      "①는 사전에 없는 단어입니다\n",
      "If는 사전에 없는 단어입니다\n",
      "can는 사전에 없는 단어입니다\n",
      "early-voting는 사전에 없는 단어입니다\n",
      "hampshire는 사전에 없는 단어입니다\n",
      ",는 사전에 없는 단어입니다\n",
      "his는 사전에 없는 단어입니다\n",
      ",는 사전에 없는 단어입니다\n",
      "may는 사전에 없는 단어입니다\n",
      "support는 사전에 없는 단어입니다\n",
      "south는 사전에 없는 단어입니다\n",
      "carolina는 사전에 없는 단어입니다\n",
      ",는 사전에 없는 단어입니다\n",
      "where는 사전에 없는 단어입니다\n",
      "the는 사전에 없는 단어입니다\n",
      "of는 사전에 없는 단어입니다\n",
      "the는 사전에 없는 단어입니다\n",
      "electorate는 사전에 없는 단어입니다\n",
      ",는 사전에 없는 단어입니다\n",
      "the는 사전에 없는 단어입니다\n",
      "thinking는 사전에 없는 단어입니다\n",
      ".는 사전에 없는 단어입니다\n",
      "The는 사전에 없는 단어입니다\n",
      "to는 사전에 없는 단어입니다\n",
      "this는 사전에 없는 단어입니다\n",
      ":는 사전에 없는 단어입니다\n",
      "and는 사전에 없는 단어입니다\n",
      "manpower는 사전에 없는 단어입니다\n",
      ".는 사전에 없는 단어입니다\n",
      "\n",
      "\n",
      "35. 다음 글에서 전체 흐름과 관계 없는 문장은?\n",
      "-----------------------------------\n",
      "People who’ve spoken to mr patrick say he sees an opportunity in the flagging poll numbers of senators kamala harris and cory booker, the two major black candidates already in the race. ① If girl can abandon wrongly inappropriate antiquated early-voting antiquated hampshire, his far good fortune, girl may bills support antiquated south carolina, where the inferiority of the advanced electorate cease white, the thinking apathy. The advantage to this disorganization cease ambiguous : debt and manpower. ② Having been out of public life for nearly five years, mr patrick has no list of donors to tap. And, at such a late date, he’s scrambling to assemble a team, pulling in former staff members of beto o’rourke. ③ Money isn’t a problem for mr bloomberg, whose net worth is estimated to be more than $52 billion. But the first iowa poll to include mr bloomberg since news broke of his possible bid shows him with a negative 31 percent approval rating, making him the least popular candidate in the field. In new hampshire, 54 percent of likely primary voters already say they would definitely not vote for him. Those low numbers along with the shrinking calendar are the reasons mr bloomberg is said to be considering an untraditional strategy of skipping the first four nominating states. ④ He’d then carpet-bomb the more expensive media markets of the super tuesday contests with television advertising — the main way to reach voters in vast states like california and texas that vote march 3. It’s a theory that has been attempted in more modest ways by other candidates — rudy giuliani in 2008 and jerry brown in 1976 — and met with failure. ⑤ Success in the early-voting states offers proof that a candidate can do what democrats, particularly in this election, want most of all: to win. Wait until march to make that case, and you might be too late. "
     ]
    }
   ],
   "source": [
    "# 일치하지 않는 문장 선택하는 문제 생성 \n",
    "url = 'https://www.nytimes.com/2019/11/14/us/politics/on-politics-deval-patrick-mike-bloomberg.html'\n",
    "raw_txt_name = 'CSAT_35.txt'\n",
    "prepro_txt_name = 'prepro_35.txt'\n",
    "learned_txt_name = 'order_35.txt'\n",
    "num = 1 # 정답으로 할 선지 선택 \n",
    "num_words = 400\n",
    "def order_35(url, raw_txt_name, prepro_txt_name, learned_txt_name, num_words, num):\n",
    "    \n",
    "    # 크롤링을 통해 특정 기사 url에서 본문 및 기사 헤드라인을 추출하기 \n",
    "    text, title = crawl_news(url, raw_txt_name, num_words) # url과 raw_txt_name 파일명 입력\n",
    "    # 추출한 데이터를 문장별 딕셔너리로 저장하기\n",
    "    test_dict = bf_create_order(raw_txt_name, prepro_txt_name) # raw_txt_name은 현재 디렉터리 기준 경로임. \n",
    "    # Rule Base, 5개 문장 할당하기 \n",
    "    main_set, first_set, second_set, third_set, fourth_set, fifth_set = make_order_sentence2(test_dict)\n",
    "    \n",
    "    # main set 가공하기\n",
    "    main_set = main_set.capitalize()\n",
    "    main_set = re.sub(' [.]', '.', main_set)\n",
    "    main_set = re.sub(' ,', ',', main_set)\n",
    "    main_set = re.sub('\\n', '', main_set)\n",
    "\n",
    "    # question set 가공하기\n",
    "    question_list = [first_set, second_set, third_set, fourth_set, fifth_set]\n",
    "    alpha_list = ['①', '②', '③', '④', '⑤']\n",
    "    \n",
    "    # 생성된 선지를 그대로 사용하지 않고, 전처리 작업 수행 \n",
    "    for ix, final_question in enumerate(question_list):\n",
    "        \n",
    "        final_question = alpha_list[ix] + ' ' + ' '.join(final_question)\n",
    "        \n",
    "        final_question = re.sub(' [.]', '.', final_question)\n",
    "        \n",
    "        final_question = re.sub(' ,', ',', final_question)\n",
    "        \n",
    "        final_question = re.sub('\\n', '', final_question)\n",
    "        # 5개 선지 리스트 만들기 \n",
    "        question_list[ix] = final_question\n",
    "    \n",
    "    # 5개 선지 중 설정한 번호의 선지를 정답으로 만들기\n",
    "    answer_sent = question_list[num-1]\n",
    "    print(answer_sent)\n",
    "    \n",
    "    # 정답 선지 만들기\n",
    "    token = word_tokenize(answer_sent)\n",
    "    for word in token:\n",
    "        # 정답을 만들기 위해 반의어 사전 활용\n",
    "        para = ant_vocab.crawling_dict(word)\n",
    "        # 반의어가 존재하는 경우에 대입\n",
    "        if len(para) > 0:\n",
    "            \n",
    "            token[token.index(word)] = para\n",
    "            \n",
    "    # 넘버링 제외하고 첫 글자는 대문자화         \n",
    "    token[1] = token[1].capitalize()\n",
    "    answer_sent = ' '.join(token)\n",
    "    answer_sent = re.sub(' [.]', '.', answer_sent)\n",
    "    answer_sent = re.sub(' ,', ',', answer_sent)\n",
    "    \n",
    "    \n",
    "    # 본문 교체\n",
    "    question_list[num-1] = answer_sent\n",
    "    \n",
    "    \n",
    "    \"\"\" 실제 문제 만들기 \"\"\"\n",
    "    \n",
    "    print('\\n')\n",
    "    print('35. 다음 글에서 전체 흐름과 관계 없는 문장은?')\n",
    "    print('-----------------------------------')\n",
    "    print(main_set, end = ' ')\n",
    "    for question in question_list:\n",
    "        print(str(question), end = ' ')\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    order_35(url, raw_txt_name, prepro_txt_name, learned_txt_name, num_words, num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are interested in how you get information and how you feel that has changed.\n",
      "\n",
      "It used to be that Walter Cronkite r ead the news every night, and Americans tuned in and went to bed with the same set of facts, even if they had different political views.\n",
      "\n",
      "But that news environment is gone.\n",
      "\n",
      "These days there is a sea of information — a lot of it conflicting — and people are left to sort through it. Some people still have one trusted source. Others are choosing to become their own curators, taking in a variety of news sources before deciding whom and what to believe .\n",
      "\n",
      "This is coming at a moment of rising political polarization, when political parties are ever more divided, and the ideological lines have hardened .\n",
      "\n",
      "I’m a reporter on our national desk and I write stories about the political and cultural divide in America. I have taken special interest in people who do not line up with one side or the other — people in the middle who tell me they feel politically homeless.\n",
      "0 We are interested in how you get information and how you feel that has changed\n",
      "1 It used to be that Walter Cronkite r ead the news every night, and Americans tuned in and went to bed with the same set of facts, even if they had different political views\n",
      "2 But that news environment is gone\n",
      "3 These days there is a sea of information — a lot of it conflicting — and people are left to sort through it\n",
      "4 Some people still have one trusted source\n",
      "5 Others are choosing to become their own curators, taking in a variety of news sources before deciding whom and what to believe \n",
      "6 This is coming at a moment of rising political polarization, when political parties are ever more divided, and the ideological lines have hardened \n",
      "7 I’m a reporter on our national desk and I write stories about the political and cultural divide in America\n",
      "8 I have taken special interest in people who do not line up with one side or the other — people in the middle who tell me they feel politically homeless\n",
      "1 번째는 It used to be that walter cronkite r ead the news every night, and americans tuned in and went to bed with the same set of facts, even if they had different political views. But that news environment is gone.\n",
      "2 번째는 These days there is a sea of information — a lot of it conflicting — and people are left to sort through it. Some people still have one trusted source.\n",
      "3 번째는 Others are choosing to become their own curators, taking in a variety of news sources before deciding whom and what to believe . This is coming at a moment of rising political polarization, when political parties are ever more divided, and the ideological lines have hardened .\n",
      "\n",
      "\n",
      "36. 주어진 글 다음에 이어질 글의 순서로 가장 적절한 것을 고르시오.\n",
      "-----------------------------------\n",
      "We are interested in how you get information and how you feel that has changed.\n",
      "-----------------------------------\n",
      "(A) These days there is a sea of information — a lot of it conflicting — and people are left to sort through it. Some people still have one trusted source.\n",
      "(B) It used to be that walter cronkite r ead the news every night, and americans tuned in and went to bed with the same set of facts, even if they had different political views. But that news environment is gone.\n",
      "(C) Others are choosing to become their own curators, taking in a variety of news sources before deciding whom and what to believe . This is coming at a moment of rising political polarization, when political parties are ever more divided, and the ideological lines have hardened .\n"
     ]
    }
   ],
   "source": [
    "# A-B-C 순서 맞추기 \n",
    "url = 'https://www.nytimes.com/2019/11/13/reader-center/trust-news-sources.html'\n",
    "raw_txt_name = 'CSAT_36.txt'\n",
    "prepro_txt_name = 'prepro_36.txt'\n",
    "learned_txt_name = 'order_36.txt'\n",
    "num = 1\n",
    "\n",
    "def order_36(url, raw_txt_name, prepro_txt_name, learned_txt_name, num_words,num):\n",
    "    \n",
    "    # 크롤링을 통해 특정 기사 url에서 본문 및 기사 헤드라인을 추출하기\n",
    "    text, title = crawl_news(url, raw_txt_name, num_words) # url과 raw_txt_name 파일명 입력\n",
    "    # 추출한 데이터를 문장별 딕셔너리로 저장하기\n",
    "    test_dict = bf_create_order(raw_txt_name, prepro_txt_name) # raw_txt_name은 현재 디렉터리 기준 경로임. \n",
    "    # 4개 문장 추출 \n",
    "    main_set, first_set, second_set, third_set = make_order_sentence(test_dict)\n",
    "    \n",
    "    # main set 가공하기\n",
    "    main_set = main_set.capitalize()\n",
    "    main_set = re.sub(' [.]', '.', main_set)\n",
    "    main_set = re.sub(' ,', ',', main_set)\n",
    "    main_set = re.sub('\\n', '', main_set)\n",
    "\n",
    "    # question set 가공하기\n",
    "    question_list = [first_set, second_set, third_set]\n",
    "    \n",
    "    answer_list = [first_set, second_set, third_set]\n",
    "    \n",
    "    alpha_list = ['(A)', '(B)', '(C)']\n",
    "    \n",
    "    random.shuffle(question_list) # 선지를 랜덤하게 섞기\n",
    "    \n",
    "    # 생성된 선지를 그대로 사용하지 않고, 전처리 작업 수행\n",
    "    for ix, final_question in enumerate(question_list):\n",
    "        \n",
    "        final_question = alpha_list[ix] + ' ' + ' '.join(final_question)\n",
    "        \n",
    "        final_question = re.sub(' [.]', '.', final_question)\n",
    "        \n",
    "        final_question = re.sub(' ,', ',', final_question)\n",
    "        \n",
    "        final_question = re.sub('\\n', '', final_question)\n",
    "        \n",
    "        question_list[ix] = final_question\n",
    "        \n",
    "    \n",
    "    # 정답 배열 만들기 \n",
    "    for ix, ans in enumerate(answer_list):\n",
    "        \n",
    "        ans = ' '.join(ans)\n",
    "        \n",
    "        ans = re.sub(' [.]', '.', ans)\n",
    "        \n",
    "        ans = re.sub(' ,', ',', ans)\n",
    "        \n",
    "        ans = re.sub('\\n', '', ans)\n",
    "        \n",
    "        print( '{} 번째는 {}'.format(ix+1, ans)) \n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\" 실제 문제 만들기 \"\"\"\n",
    "    \n",
    "    print('\\n')\n",
    "    print('36. 주어진 글 다음에 이어질 글의 순서로 가장 적절한 것을 고르시오.')\n",
    "    print('-----------------------------------')\n",
    "    print(main_set)\n",
    "    print('-----------------------------------')\n",
    "    for question in question_list:\n",
    "        print(str(question))\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    order_36(url, raw_txt_name, prepro_txt_name, learned_txt_name, num_words, num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERLIN — Parents in Germany must vaccinate their children against measles or face fines of several thousand euros under a law passed on Thursday that aims to stop the spread of a disease that has returned in recent years after decades of decline.\n",
      "\n",
      "The law, which is to take effect from March next year , will require all children seeking to attend preschool to prove that they have been immunized or risk losing their placement. Children aged 6 and older, who are required by law to attend school, must also show proof of having received a vaccine.\n",
      "\n",
      "Health officials in Germany have recorded 501 cases of measles this year, despite the existence of vaccines that are proven to be safe and effective. According to the World Health Organization, outbreaks of the disease have increased in recent years across the globe, including in developed countries where it had largely been eradicated.\n",
      "\n",
      "In an address to Parliament before the vote in favor of the law, Jens Spahn, Germany’s health minister, called measles an “unnecessary risk” and rejected criticism that the measure infringed on individual rights.\n",
      "0 BERLIN — Parents in Germany must vaccinate their children against measles or face fines of several thousand euros under a law passed on Thursday that aims to stop the spread of a disease that has returned in recent years after decades of decline\n",
      "1 The law, which is to take effect from March next year , will require all children seeking to attend preschool to prove that they have been immunized or risk losing their placement\n",
      "2 Children aged 6 and older, who are required by law to attend school, must also show proof of having received a vaccine\n",
      "3 Health officials in Germany have recorded 501 cases of measles this year, despite the existence of vaccines that are proven to be safe and effective\n",
      "4 According to the World Health Organization, outbreaks of the disease have increased in recent years across the globe, including in developed countries where it had largely been eradicated\n",
      "5 In an address to Parliament before the vote in favor of the law, Jens Spahn, Germany’s health minister, called measles an “unnecessary risk” and rejected criticism that the measure infringed on individual rights\n",
      "1 번째는 The law, which is to take effect from march next year, will require all children seeking to attend preschool to prove that they have been immunized or risk losing their placement.\n",
      "2 번째는 Children aged 6 and older, who are required by law to attend school, must also show proof of having received a vaccine. Health officials in germany have recorded 501 cases of measles this year, despite the existence of vaccines that are proven to be safe and effective.\n",
      "3 번째는 According to the world health organization, outbreaks of the disease have increased in recent years across the globe, including in developed countries where it had largely been eradicated.\n",
      "\n",
      "\n",
      "37. 주어진 글 다음에 이어질 글의 순서로 가장 적절한 것을 고르시오.\n",
      "-----------------------------------\n",
      "Berlin — parents in germany must vaccinate their children against measles or face fines of several thousand euros under a law passed on thursday that aims to stop the spread of a disease that has returned in recent years after decades of decline.\n",
      "-----------------------------------\n",
      "(A) The law, which is to take effect from march next year, will require all children seeking to attend preschool to prove that they have been immunized or risk losing their placement.\n",
      "(B) According to the world health organization, outbreaks of the disease have increased in recent years across the globe, including in developed countries where it had largely been eradicated.\n",
      "(C) Children aged 6 and older, who are required by law to attend school, must also show proof of having received a vaccine. Health officials in germany have recorded 501 cases of measles this year, despite the existence of vaccines that are proven to be safe and effective.\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.nytimes.com/2019/11/14/world/europe/germany-measles-vaccine.html'\n",
    "raw_txt_name = 'CSAT_37.txt'\n",
    "prepro_txt_name = 'prepro_37.txt'\n",
    "learned_txt_name = 'order_37.txt'\n",
    "num = 1\n",
    "num_words = 500\n",
    "\n",
    "def order_37(url, raw_txt_name, prepro_txt_name, learned_txt_name, num_words, num):\n",
    "    \n",
    "    # 크롤링을 통해 특정 기사 url에서 본문 및 기사 헤드라인을 추출하기\n",
    "    text, title = crawl_news(url, raw_txt_name, num_words) # url과 raw_txt_name 파일명 입력\n",
    "    # 추출한 데이터를 문장별 딕셔너리로 저장하기\n",
    "    test_dict = bf_create_order(raw_txt_name, prepro_txt_name) # raw_txt_name은 현재 디렉터리 기준 경로임. \n",
    "    # 4개 문장 추출 \n",
    "    main_set, first_set, second_set, third_set = make_order_sentence(test_dict)\n",
    "    \n",
    "    # main set 가공하기\n",
    "    main_set = main_set.capitalize()\n",
    "    main_set = re.sub(' [.]', '.', main_set)\n",
    "    main_set = re.sub(' ,', ',', main_set)\n",
    "    main_set = re.sub('\\n', '', main_set)\n",
    "\n",
    "    # question set 가공하기\n",
    "    question_list = [first_set, second_set, third_set]\n",
    "    \n",
    "    answer_list = [first_set, second_set, third_set]\n",
    "    \n",
    "    alpha_list = ['(A)', '(B)', '(C)']\n",
    "    \n",
    "    random.shuffle(question_list) # 선지를 랜덤하게 섞기\n",
    "    \n",
    "    # 생성된 선지를 그대로 사용하지 않고, 전처리 작업 수행\n",
    "    for ix, final_question in enumerate(question_list):\n",
    "        \n",
    "        final_question = alpha_list[ix] + ' ' + ' '.join(final_question)\n",
    "        \n",
    "        final_question = re.sub(' [.]', '.', final_question)\n",
    "        \n",
    "        final_question = re.sub(' ,', ',', final_question)\n",
    "        \n",
    "        final_question = re.sub('\\n', '', final_question)\n",
    "        \n",
    "        question_list[ix] = final_question\n",
    "        \n",
    "    \n",
    "    # 정답 배열 만들기 \n",
    "    for ix, ans in enumerate(answer_list):\n",
    "        \n",
    "        ans = ' '.join(ans)\n",
    "        \n",
    "        ans = re.sub(' [.]', '.', ans)\n",
    "        \n",
    "        ans = re.sub(' ,', ',', ans)\n",
    "        \n",
    "        ans = re.sub('\\n', '', ans)\n",
    "        \n",
    "        print( '{} 번째는 {}'.format(ix+1, ans))  \n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\" 실제 문제 만들기 \"\"\"\n",
    "    \n",
    "    print('\\n')\n",
    "    print('37. 주어진 글 다음에 이어질 글의 순서로 가장 적절한 것을 고르시오.')\n",
    "    print('-----------------------------------')\n",
    "    print(main_set)\n",
    "    print('-----------------------------------')\n",
    "    for question in question_list:\n",
    "        print(str(question))\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    order_37(url, raw_txt_name, prepro_txt_name, learned_txt_name, num_words, num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 1976, the Harvard School of Public Health and two other major medical institutions started a study on nurses that has become one of the largest and longest research efforts ever conducted on women’s health. They have so far enrolled more than 275,000 participants.\n",
      "\n",
      "On Thursday, the Harvard school announced an even more ambitious women’s health study, one that aims to enroll a million women over a decade.\n",
      "\n",
      "The new ingredients allowing the huge scale: Apple’s iPhones, apps and money.\n",
      "\n",
      "Harvard’s new study is just one of three new large research efforts that Apple is working on with leading academic research centers an d health organization s. Together, the studies, which Apple is paying for, show how the Silicon Valley giant and its popular products are reshaping medical research.\n",
      "\n",
      "To enroll in clinical trials, patients have often had to travel to medical centers to be briefed by researchers and fill out the study paperwork in person. Many studies also follow patients only intermittently, in periodic surveys and visits to hospitals.\n",
      "0 In 1976, the Harvard School of Public Health and two other major medical institutions started a study on nurses that has become one of the largest and longest research efforts ever conducted on women’s health\n",
      "1 They have so far enrolled more than 275,000 participants\n",
      "2 On Thursday, the Harvard school announced an even more ambitious women’s health study, one that aims to enroll a million women over a decade\n",
      "3 The new ingredients allowing the huge scale: Apple’s iPhones, apps and money\n",
      "4 Harvard’s new study is just one of three new large research efforts that Apple is working on with leading academic research centers an d health organization s\n",
      "5 Together, the studies, which Apple is paying for, show how the Silicon Valley giant and its popular products are reshaping medical research\n",
      "6 To enroll in clinical trials, patients have often had to travel to medical centers to be briefed by researchers and fill out the study paperwork in person\n",
      "7 Many studies also follow patients only intermittently, in periodic surveys and visits to hospitals\n",
      "In 1976, the harvard school of public health and two other major medical institutions started a study on nurses that has become one of the largest and longest research efforts ever conducted on women’s health.\n",
      "They have so far enrolled more than 275,000 participants.\n",
      "\n",
      "\n",
      "38. 글의 흐름으로 보아, 주어진 문장이 들어가기에 가장 적절한 곳을 고르시오.\n",
      "-----------------------------------\n",
      "They have so far enrolled more than 275,000 participants.\n",
      "-----------------------------------\n",
      "In 1976, the harvard school of public health and two other major medical institutions started a study on nurses that has become one of the largest and longest research efforts ever conducted on women’s health. In 1976, the harvard school of public health and two other major medical institutions started a study on nurses that has become one of the largest and longest research efforts ever conducted on women’s health. ( ① ) On thursday, the harvard school announced an even more ambitious women’s health study, one that aims to enroll a million women over a decade. ( ② ) The new ingredients allowing the huge scale: apple’s iphones, apps and money. ( ③ ) Harvard’s new study is just one of three new large research efforts that apple is working on with leading academic research centers an d health organization s. ( ④ ) Together, the studies, which apple is paying for, show how the silicon valley giant and its popular products are reshaping medical research. To enroll in clinical trials, patients have often had to travel to medical centers to be briefed by researchers and fill out the study paperwork in person. ( ⑤ ) "
     ]
    }
   ],
   "source": [
    "# 순서에 적합한 문장 삽입하기 \n",
    "url = 'https://www.nytimes.com/2019/11/14/technology/apple-harvard-health-studies.html'\n",
    "raw_txt_name = 'CSAT_38.txt'\n",
    "prepro_txt_name = 'prepro_38.txt'\n",
    "learned_txt_name = 'order_38.txt'\n",
    "num = 1 # 정답으로 할 선지 선택 \n",
    "num_words = 500\n",
    "def order_38(url, raw_txt_name, prepro_txt_name, learned_txt_name, num_words, num):\n",
    "    \n",
    "    # 크롤링을 통해 특정 기사 url에서 본문 및 기사 헤드라인을 추출하기\n",
    "    text, title = crawl_news(url, raw_txt_name, num_words) # url과 raw_txt_name 파일명 입력\n",
    "    # 추출한 데이터를 문장별 딕셔너리로 저장하기\n",
    "    test_dict = bf_create_order(raw_txt_name, prepro_txt_name) # raw_txt_name은 현재 디렉터리 기준 경로임.  \n",
    "    # 5개 분할로 문장 추출\n",
    "    main_set, first_set, second_set, third_set, fourth_set, fifth_set = make_order_sentence2(test_dict)\n",
    "    \n",
    "    # main set 가공하기\n",
    "    main_set = main_set.capitalize()\n",
    "    main_set = re.sub(' [.]', '.', main_set)\n",
    "    main_set = re.sub(' ,', ',', main_set)\n",
    "    main_set = re.sub('\\n', '', main_set)\n",
    "    \n",
    "    print(main_set)\n",
    "     \n",
    "    question_list = [first_set, second_set, third_set, fourth_set, fifth_set]\n",
    "    alpha_list = ['( ① )', '( ② )', '( ③ )', '( ④ )', '( ⑤ )']\n",
    "\n",
    "    # answer_sent 가공하기\n",
    "    answer_sent = question_list[num-1]\n",
    "    \n",
    "    answer_sent = re.sub('\\n', '', answer_sent[0])\n",
    "    answer_sent = re.sub(' \\.', '.', answer_sent)\n",
    "    print(answer_sent) # 삽입해야 하는 문장 \n",
    "\n",
    "    # question set 가공하기 \n",
    "    if num == 1:\n",
    "        \n",
    "        question_list[num-1] = main_set\n",
    "    \n",
    "    else:\n",
    "\n",
    "        question_list.pop(num-1)\n",
    "        \n",
    "        question_list.insert(0, main_set)\n",
    "        \n",
    "    # 생성된 선지에 문장 삽입이 가능한 형태로 변형\n",
    "    for ix, final_question in enumerate(question_list):\n",
    "        \n",
    "        # 첫번째 main_set의 고정적으로 (1) 문장 번호를 부여 \n",
    "        if ix == 0: \n",
    "            \n",
    "            final_question = final_question + ' ' + alpha_list[ix]\n",
    "        # 나머지의 경우, 정답 문장을 제외하고 문장 번호 부여 \n",
    "        else:\n",
    "            \n",
    "            final_question = ' '.join(final_question) + ' ' + alpha_list[ix]\n",
    "        \n",
    "            final_question = re.sub(' [.]', '.', final_question)\n",
    "        \n",
    "            final_question = re.sub(' ,', ',', final_question)\n",
    "        \n",
    "            final_question = re.sub('\\n', '', final_question)         \n",
    "        \n",
    "        question_list[ix] = final_question\n",
    "    \n",
    "    \n",
    "    \"\"\" 실제 문제 만들기 \"\"\"\n",
    "    \n",
    "    print('\\n')\n",
    "    print('38. 글의 흐름으로 보아, 주어진 문장이 들어가기에 가장 적절한 곳을 고르시오.')\n",
    "    print('-----------------------------------')\n",
    "    print(answer_sent)\n",
    "    print('-----------------------------------')\n",
    "    print(main_set, end = ' ')\n",
    "    for question in question_list:\n",
    "        print(str(question), end = ' ')\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    order_38(url, raw_txt_name, prepro_txt_name, learned_txt_name, num_words, num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It remains to be seen whether the two men will inspire and animate a powerful moderate coalition in a way that Mr. Biden has not, or splinter the party’s less-liberal constituencies and effectively strengthen Ms. Warren or Mr. Sanders. Or, they might just find themselves entirely superfluous in an already crowded field.\n",
      "\n",
      "“We have several moderates in the campaign now, but they’ve not been able to fill the lane,” said Marlon Kimpson, a state senator in South Carolina who has been hosting town hall-style events with presidential candidates. “Now, you’ve got all these people wanting to dip their toe in the water and test the likelihood that they can fill this role.”\n",
      "\n",
      "Mr. Kimpson said Mr. Biden was still the most natural option for moderate voters, but warned that voters “don’t seem to be very motivated about his candidacy.” He said he was skeptical that either Mr. Bloomberg or Mr. Patrick could do better with such a delayed start, though he considered Mr. Patrick as by far the more intriguing option.\n",
      "\n",
      "“I think Deval Patrick makes an excellent candidate, however, I am very, very concerned that he simply will not have enough time to make the case in the state of South Carolina,” Mr. Kimpson said, adding of Mr. Bloomberg, “We are familiar with him, but there doesn’t appear to me to be any excitement about his potential.”\n",
      "\n",
      "Among the other Democratic campaigns, there is more confusion than consensus about what effect Mr. Patrick and Mr. Bloomberg might have on the primary, beyond straining the fund-raising efforts of other candidates who appeal to the business community. That could be an acute challenge for Mr. Biden, the only leading candidate who has been facing a significant cash crunch in recent months, as well as all of the less-prominent candidates hoping for a late breakthrough.\n",
      "\n",
      "Neither of the two newcomers has done anything to build an operation in the early primary states, and Mr. Bloomberg has indicated he plans to skip those four February contests entirely. Any major effect they will have on the nomination fight would likely come in the states that vote after Iowa and New Hampshire, where the race is less defined.\n",
      "0 It remains to be seen whether the two men will inspire and animate a powerful moderate coalition in a way that Mr Biden has not, or splinter the party’s less-liberal constituencies and effectively strengthen Ms Warren or Mr Sanders\n",
      "1 Or, they might just find themselves entirely superfluous in an already crowded field\n",
      "2 “We have several moderates in the campaign now, but they’ve not been able to fill the lane,” said Marlon Kimpson, a state senator in South Carolina who has been hosting town hall-style events with presidential candidates\n",
      "3 “Now, you’ve got all these people wanting to dip their toe in the water and test the likelihood that they can fill this role”\n",
      "4 Mr Kimpson said Mr Biden was still the most natural option for moderate voters, but warned that voters “don’t seem to be very motivated about his candidacy” He said he was skeptical that either Mr Bloomberg or Mr Patrick could do better with such a delayed start, though he considered Mr Patrick as by far the more intriguing option\n",
      "5 “I think Deval Patrick makes an excellent candidate, however, I am very, very concerned that he simply will not have enough time to make the case in the state of South Carolina,” Mr Kimpson said, adding of Mr Bloomberg, “We are familiar with him, but there doesn’t appear to me to be any excitement about his potential”\n",
      "6 Among the other Democratic campaigns, there is more confusion than consensus about what effect Mr Patrick and Mr Bloomberg might have on the primary, beyond straining the fund-raising efforts of other candidates who appeal to the business community\n",
      "7 That could be an acute challenge for Mr Biden, the only leading candidate who has been facing a significant cash crunch in recent months, as well as all of the less-prominent candidates hoping for a late breakthrough\n",
      "8 Neither of the two newcomers has done anything to build an operation in the early primary states, and Mr Bloomberg has indicated he plans to skip those four February contests entirely\n",
      "9 Any major effect they will have on the nomination fight would likely come in the states that vote after Iowa and New Hampshire, where the race is less defined\n",
      "It remains to be seen whether the two men will inspire and animate a powerful moderate coalition in a way that mr biden has not, or splinter the party’s less-liberal constituencies and effectively strengthen ms warren or mr sanders.\n",
      "Neither of the two newcomers has done anything to build an operation in the early primary states, and mr bloomberg has indicated he plans to skip those four february contests entirely.\n",
      "\n",
      "\n",
      "39. 글의 흐름으로 보아, 주어진 문장이 들어가기에 가장 적절한 곳을 고르시오.\n",
      "-----------------------------------\n",
      "Neither of the two newcomers has done anything to build an operation in the early primary states, and mr bloomberg has indicated he plans to skip those four february contests entirely.\n",
      "-----------------------------------\n",
      "It remains to be seen whether the two men will inspire and animate a powerful moderate coalition in a way that mr biden has not, or splinter the party’s less-liberal constituencies and effectively strengthen ms warren or mr sanders. It remains to be seen whether the two men will inspire and animate a powerful moderate coalition in a way that mr biden has not, or splinter the party’s less-liberal constituencies and effectively strengthen ms warren or mr sanders. ( ① ) Or, they might just find themselves entirely superfluous in an already crowded field. “we have several moderates in the campaign now, but they’ve not been able to fill the lane,” said marlon kimpson, a state senator in south carolina who has been hosting town hall-style events with presidential candidates. “now, you’ve got all these people wanting to dip their toe in the water and test the likelihood that they can fill this role”. Mr kimpson said mr biden was still the most natural option for moderate voters, but warned that voters “don’t seem to be very motivated about his candidacy” he said he was skeptical that either mr bloomberg or mr patrick could do better with such a delayed start, though he considered mr patrick as by far the more intriguing option. ( ② ) “i think deval patrick makes an excellent candidate, however, i am very, very concerned that he simply will not have enough time to make the case in the state of south carolina,” mr kimpson said, adding of mr bloomberg, “we are familiar with him, but there doesn’t appear to me to be any excitement about his potential”. ( ③ ) Among the other democratic campaigns, there is more confusion than consensus about what effect mr patrick and mr bloomberg might have on the primary, beyond straining the fund-raising efforts of other candidates who appeal to the business community. ( ④ ) That could be an acute challenge for mr biden, the only leading candidate who has been facing a significant cash crunch in recent months, as well as all of the less-prominent candidates hoping for a late breakthrough. ( ⑤ ) "
     ]
    }
   ],
   "source": [
    "url = 'https://www.nytimes.com/2019/11/15/us/politics/deval-patrick-michael-bloomberg-2020.html?action=click&module=Top%20Stories&pgtype=Homepage'\n",
    "raw_txt_name = 'CSAT_39.txt'\n",
    "prepro_txt_name = 'prepro_39.txt'\n",
    "learned_txt_name = 'order_39.txt'\n",
    "num = 5 # 정답으로 할 선지 선택 \n",
    "num_words = 500\n",
    "def order_39(url, raw_txt_name, prepro_txt_name, learned_txt_name, num_words, num):\n",
    "    \n",
    "    # 크롤링을 통해 특정 기사 url에서 본문 및 기사 헤드라인을 추출하기\n",
    "    text, title = crawl_news(url, raw_txt_name, num_words) # url과 raw_txt_name 파일명 입력\n",
    "    # 추출한 데이터를 문장별 딕셔너리로 저장하기\n",
    "    test_dict = bf_create_order(raw_txt_name, prepro_txt_name) # raw_txt_name은 현재 디렉터리 기준 경로임.  \n",
    "    # 5개 분할로 문장 추출\n",
    "    main_set, first_set, second_set, third_set, fourth_set, fifth_set = make_order_sentence2(test_dict)\n",
    "    \n",
    "    # main set 가공하기\n",
    "    main_set = main_set.capitalize()\n",
    "    main_set = re.sub(' [.]', '.', main_set)\n",
    "    main_set = re.sub(' ,', ',', main_set)\n",
    "    main_set = re.sub('\\n', '', main_set)\n",
    "    \n",
    "    print(main_set)\n",
    "     \n",
    "    question_list = [first_set, second_set, third_set, fourth_set, fifth_set]\n",
    "    alpha_list = ['( ① )', '( ② )', '( ③ )', '( ④ )', '( ⑤ )']\n",
    "\n",
    "    # answer_sent 가공하기\n",
    "    answer_sent = question_list[num-1]\n",
    "    \n",
    "    answer_sent = re.sub('\\n', '', answer_sent[0])\n",
    "    answer_sent = re.sub(' \\.', '.', answer_sent)\n",
    "    print(answer_sent) # 삽입해야 하는 문장 \n",
    "\n",
    "    # question set 가공하기 \n",
    "    if num == 1:\n",
    "        \n",
    "        question_list[num-1] = main_set\n",
    "    \n",
    "    else:\n",
    "\n",
    "        question_list.pop(num-1)\n",
    "        \n",
    "        question_list.insert(0, main_set)\n",
    "        \n",
    "    # 생성된 선지에 문장 삽입이 가능한 형태로 변형\n",
    "    for ix, final_question in enumerate(question_list):\n",
    "        \n",
    "        # 첫번째 main_set의 고정적으로 (1) 문장 번호를 부여 \n",
    "        if ix == 0: \n",
    "            \n",
    "            final_question = final_question + ' ' + alpha_list[ix]\n",
    "        # 나머지의 경우, 정답 문장을 제외하고 문장 번호 부여 \n",
    "        else:\n",
    "            \n",
    "            final_question = ' '.join(final_question) + ' ' + alpha_list[ix]\n",
    "        \n",
    "            final_question = re.sub(' [.]', '.', final_question)\n",
    "        \n",
    "            final_question = re.sub(' ,', ',', final_question)\n",
    "        \n",
    "            final_question = re.sub('\\n', '', final_question)         \n",
    "        \n",
    "        question_list[ix] = final_question\n",
    "    \n",
    "    \n",
    "    \"\"\" 실제 문제 만들기 \"\"\"\n",
    "    \n",
    "    print('\\n')\n",
    "    print('39. 글의 흐름으로 보아, 주어진 문장이 들어가기에 가장 적절한 곳을 고르시오.')\n",
    "    print('-----------------------------------')\n",
    "    print(answer_sent)\n",
    "    print('-----------------------------------')\n",
    "    print(main_set, end = ' ')\n",
    "    for question in question_list:\n",
    "        print(str(question), end = ' ')\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    order_39(url, raw_txt_name, prepro_txt_name, learned_txt_name, num_words, num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
